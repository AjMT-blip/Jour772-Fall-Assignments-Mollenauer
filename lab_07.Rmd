---
title: "lab_07"
author: "derek willis"
date: "2023-03-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

-   A Census API key

## Load libraries and establish settings

You'll need to load two packages for this: the tidyverse and tidycensus.

**Task** load these two packages

```{r}
# Turn off scientific notation
options(scipen=999)

library(tidyverse)
library(janitor)
library(lubridate)
library(tidycensus)
library(dplyr)
```

## Setup Census API

You'll need your Census API Key: abf156aa59918cbc763c26c9765fdf7e333d2745

**Task** set your API Key if you haven't already. You won't need to install or overwrite it.

```{r echo=FALSE}
census_api_key("abf156aa59918cbc763c26c9765fdf7e333d2745", install=TRUE, overwrite = TRUE)
```

## Load and view ACS variables

You'll also need to load the list of American Community Survey variables from the 2022 5-year estimates so you can identify the codes you need:

**Task** load the variables from the 2022 5-year ACS (which is called "acs5") and save them to a dataframe

```{r}
v21 <- load_variables(2021, "acs5", cache=TRUE)
```

## Answer questions

#### **Q1** What is the Maryland jurisdiction with the lowest median age, according to the ACS 2021 5-year estimates? You will need to find the variable for median age first (search for it in the 'concept' column at the data frame we just created).

```{r}
median_age <- v21 |>
  filter(concept == "MEDIAN AGE")
median_age

md_data <- get_acs(geography = "county",
                   variables = c(medage = "B01002_001"),
                   year = 2021)

lowest_med_age <- md_data |>
  arrange(estimate)

lowest_med_age
```

**Answer here: It appears to be 35.7, which is listed as Baltimore City.**

------------------------------------------------------------------------

#### **Q2** Which Maryland counties have a median age of at least 50? You can use the dataframe you just made to answer this, but you must write code to display only those counties with a median age of at least 50. **A2**

```{r}
median_50 <- md_data |>
  filter(estimate >= 50)
median_50
```

**Answer here: I see only Worcester County here, and I'm still unsure how to go about new code to illustrate this because the syntax I have originally is what I understood to be the correct command/syntax to specify Maryland.**

------------------------------------------------------------------------

#### **Q3** We're interested in knowing more about Montgomery County zip codes where overdose calls are coming from and the demographic characteristics they possess. In particular, we want to calculate a rate of calls per 1,000 population. To do this, you'll need to:

1.  Load the Montgomery County 911 overdose calls data.
2.  Create a new dataframe with the total number of calls for each zip code.
3.  Find the ACS variable pertaining to the total 18 and up population (there are several choices here; you want the simplest one).
4.  Get from the ACS data from all Maryland zip codes using that variable.
5.  Join the ACS data to the Montgomery County zip code totals dataframe and rename the estimate column to a meaningful name you've given the ACS variable.
6.  Add a column to the joined dataframe that calculates a rate of calls per 1,000 population.

Which zip code has the highest rate of calls? Which has the lowest?

```{r}
calls_zip_code <- montgomery_2022_overdoses|>
  group_by(zip)|>
  summarise(total_calls = n())

acs_variable <- "B01001_001"

md_population_data <- get_acs(
  geography = "zip code tabulation area",
  variables = "B01001_001",
  year = 2021
)

calls_and_population <- calls_zip_code|>
  mutate(zip = as.character(zip))|>
  left_join(md_population_data|>
              select(GEOID, estimate), by = c("zip" = "GEOID"))|>
  rename(pop_18_and_up = estimate)

calls_and_population <- calls_and_population|>
  mutate(calls_per_1000 = (total_calls / pop_18_and_up) * 1000)

calls_and_population
```

**Answer here: 20889, which indicates a call rate of approximately 2.46 per 1,000 people.**

------------------------------------------------------------------------

#### **Q4** Using [CensusReporter.org](https://censusreporter.org/), examine the zip codes on Q3 with the highest and lowest rates and compare and contrast their demographic profiles. Is there a story here?

**Answer here: .022 is the call rate per 1,000 for zip code 20707, which is for Laurel, MD, which is majority minority, according to Data USA. 20889, the zip code for Bethesda, represents a majority white area, which in this case had the highest number of calls. At least upon first thought, I don't see a story here, because the trend I would have expected is not the case. I would have expected this to be the reverse, or the majority minority community having more calls, my reason being because such communities face more hardships generally in terms of higher poverty and fewer resources due to government neglecting those citizens at disproportionately higher rates.**

------------------------------------------------------------------------

#### **Q5** Go back to your joined dataframe from Q3 and add two more columns representing the minimum and maximum populations based on the estimate and margin of error, then calculate per capita rates for each. Do you get the same two zip codes for the highest and lowest as you did before? Does that give you more or less confidence in your answers to Q3?

```{r}
calls_and_population <- calls_zip_code|>
  mutate(zip = as.character(zip))|>
  left_join(md_population_data|> select(GEOID, estimate, moe), by = c("zip" = "GEOID"))|>
  rename(pop_18_and_up = estimate)

calls_and_population <- calls_and_population|>
  mutate(
    min_pop = pop_18_and_up - moe,
    max_pop = pop_18_and_up + moe,
    calls_per_1000_min = (total_calls / min_pop) * 1000,
    calls_per_1000_max = (total_calls / max_pop) * 1000
  )

calls_and_population
```

**Answer here: Each of those two zip codes have just one call each, according to this new chart. So, the answer would be no for the highest and technically same for the lowest, which is a multiple-way tie for 1 among a handful of zip codes. Because of the pretty drastic difference, I don't have as much confidence in that initial answer now.**
